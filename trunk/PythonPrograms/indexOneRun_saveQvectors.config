# Configuration file for ReduceOneSCD_Run.py and ReduceSCD_Parallel.py.
#
# Each line can either start with a comment, indicated by a '#' mark or start
# with a parameter name and value, optionally followed by a comment.  ALL 
# parameters used by the script must be specified.  If a required parameter 
# is not specified, the script will terminate with a message indicating which 
# parameter was missing.
#

# ==========================================================================
# Parameters needed by ReduceOneSCD_Run.py, to process ONE run.
# ==========================================================================
#
instrument_name   TOPAZ                        # prefix for run file names

#
# Set the data_directory to None to use findnexus to get the run file when
# running this on the SNS systems.  On other systems, all of the input files
# must be copied into one directory and that directory must be specified as
# the data_directory
#
data_directory    /SNS/TOPAZ/IPTS-5431/data       
output_directory  /SNS/users/ajschultz/triphylite

#
# If True, after loading the NeXus file, save the events as Q vectors in a
# binary file by running the Mantid algorithm SaveIsawQvector. This can also
# be accomplished by independently running the script SaveIsawQvector.py.
save_Q_vectors   True

#
# min & max tof determine range of events loaded and also the range of tofs 
# integrated in the monitor data to get the total monitor counts
#
min_tof         2000
max_tof        16500
monitor_index      0

#
# Specifiy a conventional cell type and centering.  If these are None, only
# one .mat and .integrate file will be written for this run, and they will
# be in terms of the Niggli reduced cell.  If these specifiy a valid
# cell type and centering, an additional .mat and .integrate file will be
# written for the specified cell_type and centering.  NOTE: If run in
# parallel, the driving script will only read the Niggli version of the
# .integrate file, and will combine, re-index and convert to a conventional
# cell, so these can usually be left as None.
#
cell_type     Orthorhombic 
centering     P 

#
# It may be necessary to further transform the cell to be compatible
# with a previous assignment.
#
apply_transform_to_hkl     True
HKL_Transform_matrix       0,0,-1,0,1,0,1,0,0


#
# Number of peaks to find, per run, both for getting the UB matrix,
# AND to determine how many peaks are integrated, if peak positions are
# NOT predicted.  NOTE: This number must be choosen carefully.  If too
# many peaks are requested, find peaks will take a very long time and
# the returned peaks will probably not even index, since most of them
# will be "noise" peaks.  If too few are requested, then there will be
# few peaks to be integrated, and the UB matrix may not be as accurate 
# as it should be for predicting peaks to integrate.
#
num_peaks_to_find  100 

#
# min_d, max_d and tolerance control indexing peaks.  max_d is also 
# used to specify a threshold for the separation between peaks
# returned by FindPeaksMD, so it should be specified somewhat larger
# than the largest cell edge in the Niggli reduced cell for the 
# sample.
#
min_d         4
max_d        12
tolerance  0.12

# ==========================================================================
# Additional Parameters needed by ReduceSCD_Parallel.py, to process
# multiple runs in parallel.
# ==========================================================================
#
exp_name               triphylite               
reduce_one_run_script  IndexOneSCD_Run.py

#
# Specify the run numbers that should be reduced.  This can be done on several
# lines.  Each line must start with the parameter name run_nums and be followed
# by a comma separated list of individual run numbers or ranges of run numbers.
# A range of run numbers is specified by listing the first number and last
# number in the range, separated by a colon.
#
run_nums  3131:3145

#
# Specify the slurm partion, or None to use local processes.  The parameter
# max_processes controls the maximum number of processes that will be run 
# simultaneously locally, or that will be simultaneously submitted to slurm.
# The value of max_processes should be choosen carefully with the size of the
# system in mind, to avoid overloading the system.  Since the lower level 
# calculations are all multi-threaded, this should be substantially lower than
# the total number of cores available.
# All runs will be processed eventually.  If there are more runs than then
# max_processes, as some processes finish, new ones will be started, until
# all runs have been processed.
#
slurm_queue_name    None
max_processes       8

